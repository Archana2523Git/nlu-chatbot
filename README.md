# NLP Chatbot with Local LLM (Ollama) ğŸ¤–ğŸ§ 

ğŸ“Œ **Project Overview**  
This is a locally hosted NLP chatbot system that uses a **custom NLU model** for intent classification and a **local LLM via Ollama** for context-aware responses. The project has a **Python backend** for NLU/LLM processing and a **React frontend** for an interactive chat interface.

It runs completely offlineâ€”no external API keys are required.

---

## ğŸ§© Architecture

```text
User Input (Frontend)
       â†“
Intent Classifier (Python NLU)
       â†“
Intent-aware Prompt
       â†“
Ollama Local LLM
       â†“
Response Display (Frontend)
ğŸš€ Features

Intent classification using labeled datasets

Local LLM inference (offline, secure, no cloud API)

Interactive React frontend for chatting with the bot

Modular design for adding new intents or LLM logic

Easy evaluation of intent classification accuracy

ğŸ› ï¸ Tech Stack

Frontend: React, Vite, HTML, CSS, JavaScript

Backend: Python 3.10+, Streamlit (optional), Ollama, Scikit-learn

Database: JSON-based datasets (intents.json, eval_dataset.json)

Version Control: Git & GitHub

ğŸ“‚ Project Structure
nlp-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # Main backend entry
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ nlu/                 # Custom NLU model logic
â”‚   â”œâ”€â”€ services/            # Additional backend services
â”‚   â””â”€â”€ venv/                # Python virtual environment
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/                 # React source code
â”‚   â”œâ”€â”€ public/              # Static files
â”‚   â”œâ”€â”€ index.html           # Main HTML
â”‚   â”œâ”€â”€ package.json         # Node dependencies
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md
âš™ï¸ Setup Instructions
1ï¸âƒ£ Backend Setup
cd backend
python -m venv venv          # Create virtual environment
venv\Scripts\activate        # Activate (Windows)
# or source venv/bin/activate  # macOS/Linux
pip install -r requirements.txt

Start backend server (example):

python main.py
2ï¸âƒ£ Frontend Setup
cd frontend
npm install                  # Install Node dependencies
npm run dev                  # Start React frontend

Open your browser at http://localhost:5173 (default Vite port) to interact with the bot.

ğŸ§ª Evaluation

Evaluate NLU intent classification using your test dataset.

Backend will provide predicted intents and LLM responses.

Metrics include accuracy and optional confusion matrix (if implemented).

ğŸ”® Future Improvements

Multi-intent handling

Conversation context memory across messages

Fine-tuning the LLM locally for domain-specific intents

Docker-based deployment for easy sharing
